# NLP model for classifying NLI sentences on Kaggle's competition

Natural language inference is the task of determining whether a “hypothesis” is true (entailment), false (contradiction), or undetermined (neutral) given a “premise”. In this project we tried to develop a model which uses pre-trained neural models (BERT based) that aims to achieve the best results as possible on a given dataset from Kaggle competition. In order to achieve it, we explored different Bert models, added more data (Mnli, Snli, Xnli), exmined training techniques and tried different fine-tuning NN-architectures. Our best model achieves 94.28\% accuracy (top 7\% in the competition). 
This project has been used to implement our paper [Adapting by Pruning: A Case Study on BERT](https://github.com/orsho/NLI-kaggle-competition-/blob/main/NLP_Project_on_NLI_using_BERT%20.pdf). Please cite this paper when you use this project.
